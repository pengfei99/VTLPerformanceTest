{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-18T10:31:21.101505676Z",
     "start_time": "2023-12-18T10:31:21.050379722Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession,DataFrame\n",
    "from pyspark.sql.types import StructField, StructType, StringType, DoubleType, IntegerType, LongType, DecimalType\n",
    "import os\n",
    "from pyspark.sql.functions import lit, count,sum,avg,collect_list,min,max,percentile_approx,stddev_pop,stddev_samp,var_pop,var_samp,first,last,col\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/12/18 10:44:27 WARN Utils: Your hostname, pengfei-Virtual-Machine resolves to a loopback address: 127.0.1.1; using 10.50.2.80 instead (on interface eth0)\n",
      "23/12/18 10:44:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/12/18 10:44:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "local = True\n",
    "\n",
    "if local:\n",
    "    spark = SparkSession.builder \\\n",
    "        .master(\"local[4]\") \\\n",
    "        .appName(\"VTLAnalytic\")\\\n",
    "        .getOrCreate()\n",
    "else:\n",
    "    spark = SparkSession.builder\\\n",
    "        .master(\"k8s://https://kubernetes.default.svc:443\") \\\n",
    "        .appName(\"VTLAnalytic\")\\\n",
    "        .config(\"spark.kubernetes.container.image\", \"inseefrlab/jupyter-datascience:py3.9.7-spark3.2.0\")\\\n",
    "        .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\", os.environ['KUBERNETES_SERVICE_ACCOUNT'])\\\n",
    "        .config(\"spark.executor.instances\", \"4\")\\\n",
    "        .config(\"spark.executor.memory\", \"8g\")\\\n",
    "        .config(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE'])\\\n",
    "        .getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T09:44:36.258318029Z",
     "start_time": "2023-12-18T09:44:23.141199593Z"
    }
   },
   "id": "74521bccd0a2871"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+----+----+\n",
      "|Id_1|Id_2|Year|Me_1|Me_2|\n",
      "+----+----+----+----+----+\n",
      "|   A|  XX|2000|   3| 1.0|\n",
      "|   A|  XX|2001|   4| 9.0|\n",
      "|   A|  XX|2002|   7| 5.0|\n",
      "|   A|  XX|2003|   6| 8.0|\n",
      "|   A|  YY|2000|   9| 3.0|\n",
      "|   A|  YY|2001|   5| 4.0|\n",
      "|   A|  YY|2002|  10| 2.0|\n",
      "|   A|  YY|2003|   5| 7.0|\n",
      "+----+----+----+----+----+\n"
     ]
    }
   ],
   "source": [
    "data1=[(\"A\", \"XX\", 2000, 3, 1.0),\n",
    "    (\"A\", \"XX\", 2001, 4, 9.0),\n",
    "    (\"A\", \"XX\", 2002, 7, 5.0),\n",
    "    (\"A\", \"XX\", 2003, 6, 8.0),\n",
    "    (\"A\", \"YY\", 2000, 9, 3.0),\n",
    "    (\"A\", \"YY\", 2001, 5, 4.0),\n",
    "    (\"A\", \"YY\", 2002, 10, 2.0),\n",
    "    (\"A\", \"YY\", 2003, 5, 7.0)]\n",
    "\n",
    "schema1=StructType([StructField(\"Id_1\",StringType(),True),\n",
    "                   StructField(\"Id_2\",StringType(),True),\n",
    "                   StructField(\"Year\",IntegerType(),True),\n",
    "                   StructField(\"Me_1\",IntegerType(),True),\n",
    "                   StructField(\"Me_2\",DoubleType(),True)])\n",
    "\n",
    "ds1=spark.createDataFrame(data1, schema1)\n",
    "ds1.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T09:44:50.532496192Z",
     "start_time": "2023-12-18T09:44:42.192457043Z"
    }
   },
   "id": "22584af75b54fb47"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+----+----+\n",
      "|Id_1|Id_2|Year|Me_1|Me_2|\n",
      "+----+----+----+----+----+\n",
      "|   A|  XX|1993|   3| 1.0|\n",
      "|   A|  XX|1994|   4| 9.0|\n",
      "|   A|  XX|1995|   7| 5.0|\n",
      "|   A|  XX|1996|   6| 8.0|\n",
      "|   A|  YY|1993|   9| 3.0|\n",
      "|   A|  YY|1994|   5| 4.0|\n",
      "|   A|  YY|1995|  10| 2.0|\n",
      "|   A|  YY|1996|   2| 7.0|\n",
      "+----+----+----+----+----+\n"
     ]
    }
   ],
   "source": [
    "data2=[(\"A\", \"XX\", 1993, 3, 1.0),\n",
    "    (\"A\", \"XX\", 1994, 4, 9.0),\n",
    "    (\"A\", \"XX\", 1995, 7, 5.0),\n",
    "    (\"A\", \"XX\", 1996, 6, 8.0),\n",
    "    (\"A\", \"YY\", 1993, 9, 3.0),\n",
    "    (\"A\", \"YY\", 1994, 5, 4.0),\n",
    "    (\"A\", \"YY\", 1995, 10, 2.0),\n",
    "    (\"A\", \"YY\", 1996, 2, 7.0)]\n",
    "\n",
    "\n",
    "schema2=StructType([StructField(\"Id_1\",StringType(),True),\n",
    "                   StructField(\"Id_2\",StringType(),True),\n",
    "                   StructField(\"Year\",IntegerType(),True),\n",
    "                   StructField(\"Me_1\",IntegerType(),True),\n",
    "                   StructField(\"Me_2\",DoubleType(),True)])\n",
    "\n",
    "ds2=spark.createDataFrame(data2, schema2)\n",
    "ds2.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T09:48:43.200432960Z",
     "start_time": "2023-12-18T09:48:42.575996579Z"
    }
   },
   "id": "ea8d58fcf90ce0cf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fist function\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "# input\n",
    "+----+----+----+----+----+\n",
    "|Id_1|Id_2|Year|Me_1|Me_2|\n",
    "+----+----+----+----+----+\n",
    "|   A|  XX|1993|   3| 1.0|\n",
    "|   A|  XX|1994|   4| 9.0|\n",
    "|   A|  XX|1995|   7| 5.0|\n",
    "|   A|  XX|1996|   6| 8.0|\n",
    "|   A|  YY|1993|   9| 3.0|\n",
    "|   A|  YY|1994|   5| 4.0|\n",
    "|   A|  YY|1995|  10| 2.0|\n",
    "|   A|  YY|1996|   2| 7.0|\n",
    "+----+----+----+----+----+\n",
    "\n",
    "# output\n",
    "+----+----+----+----+----+----------+----------+\n",
    "|Id_1|Id_2|Year|Me_1|Me_2|first_Me_1|first_Me_2|\n",
    "+----+----+----+----+----+----------+----------+\n",
    "|   A|  XX|1993|   3| 1.0|         3|       1.0|\n",
    "|   A|  YY|1993|   9| 3.0|         3|       1.0|\n",
    "|   A|  XX|1994|   4| 9.0|         3|       1.0|\n",
    "|   A|  YY|1994|   5| 4.0|         3|       1.0|\n",
    "|   A|  XX|1995|   7| 5.0|         4|       9.0|\n",
    "|   A|  YY|1995|  10| 2.0|         4|       9.0|\n",
    "|   A|  XX|1996|   6| 8.0|         7|       5.0|\n",
    "|   A|  YY|1996|   2| 7.0|         7|       5.0|\n",
    "+----+----+----+----+----+----------+----------+\n",
    "```\n",
    "\n",
    "\n",
    "VTL: `res := first_value ( ds2 over ( partition by Id_1 order by Year range between -1 preceding and 1 following) );`\n",
    "spark: `df = ds2.withColumn`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e51e5ba5e3d3bcca"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "win_with_custom_range = Window.partitionBy(\"Id_1\").orderBy(\"Year\").rangeBetween(-1,1)\n",
    "res = ds2.withColumn(\"first_Me_1\", first(col(\"Me_1\")).over(win_with_custom_range))\\\n",
    "         .withColumn(\"first_Me_2\", first(col(\"Me_2\")).over(win_with_custom_range))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T10:33:06.199925794Z",
     "start_time": "2023-12-18T10:33:06.105931143Z"
    }
   },
   "id": "a1c7ecf37ae50803"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+----+----+----------+----------+\n",
      "|Id_1|Id_2|Year|Me_1|Me_2|first_Me_1|first_Me_2|\n",
      "+----+----+----+----+----+----------+----------+\n",
      "|   A|  XX|1993|   3| 1.0|         3|       1.0|\n",
      "|   A|  YY|1993|   9| 3.0|         3|       1.0|\n",
      "|   A|  XX|1994|   4| 9.0|         3|       1.0|\n",
      "|   A|  YY|1994|   5| 4.0|         3|       1.0|\n",
      "|   A|  XX|1995|   7| 5.0|         4|       9.0|\n",
      "|   A|  YY|1995|  10| 2.0|         4|       9.0|\n",
      "|   A|  XX|1996|   6| 8.0|         7|       5.0|\n",
      "|   A|  YY|1996|   2| 7.0|         7|       5.0|\n",
      "+----+----+----+----+----+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "res.show(20)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T10:33:07.557163693Z",
     "start_time": "2023-12-18T10:33:07.022375489Z"
    }
   },
   "id": "d6f24dbc95c6f67f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "91c15febdb16cdce"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
