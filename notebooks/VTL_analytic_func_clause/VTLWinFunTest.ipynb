{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T10:31:21.101505676Z",
     "start_time": "2023-12-18T10:31:21.050379722Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession,DataFrame\n",
    "from pyspark.sql.types import StructField, StructType, StringType, DoubleType, IntegerType, LongType, DecimalType\n",
    "import os\n",
    "from pyspark.sql.functions import lit, count,sum,avg,collect_list,min,max,percentile_approx,stddev_pop,stddev_samp,var_pop,var_samp,first,last,col\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74521bccd0a2871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T09:44:36.258318029Z",
     "start_time": "2023-12-18T09:44:23.141199593Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/12/18 10:44:27 WARN Utils: Your hostname, pengfei-Virtual-Machine resolves to a loopback address: 127.0.1.1; using 10.50.2.80 instead (on interface eth0)\n",
      "23/12/18 10:44:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/12/18 10:44:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "local = True\n",
    "\n",
    "if local:\n",
    "    spark = SparkSession.builder \\\n",
    "        .master(\"local[4]\") \\\n",
    "        .appName(\"VTLAnalytic\")\\\n",
    "        .getOrCreate()\n",
    "else:\n",
    "    spark = SparkSession.builder\\\n",
    "        .master(\"k8s://https://kubernetes.default.svc:443\") \\\n",
    "        .appName(\"VTLAnalytic\")\\\n",
    "        .config(\"spark.kubernetes.container.image\", \"inseefrlab/jupyter-datascience:py3.9.7-spark3.2.0\")\\\n",
    "        .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\", os.environ['KUBERNETES_SERVICE_ACCOUNT'])\\\n",
    "        .config(\"spark.executor.instances\", \"4\")\\\n",
    "        .config(\"spark.executor.memory\", \"8g\")\\\n",
    "        .config(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE'])\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3608eafea49cfec6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T13:37:38.612645625Z",
     "start_time": "2023-12-18T13:37:38.240574219Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----+----+----+\n",
      "|Row_id|Id_2|Year|Me_1|Me_2|\n",
      "+------+----+----+----+----+\n",
      "|     1|  XX|1993|   3| 1.0|\n",
      "|     2|  XX|1994|   4| 9.0|\n",
      "|     3|  XX|1995|   7| 5.0|\n",
      "+------+----+----+----+----+\n"
     ]
    }
   ],
   "source": [
    "test_data=[(\"1\", \"XX\", 1993, 3, 1.0),\n",
    "    (\"2\", \"XX\", 1994, 4, 9.0),\n",
    "    (\"3\", \"XX\", 1995, 7, 5.0)]\n",
    "\n",
    "\n",
    "test_schema=StructType([StructField(\"Row_id\",StringType(),True),\n",
    "                   StructField(\"Id_2\",StringType(),True),\n",
    "                   StructField(\"Year\",IntegerType(),True),\n",
    "                   StructField(\"Me_1\",IntegerType(),True),\n",
    "                   StructField(\"Me_2\",DoubleType(),True)])\n",
    "\n",
    "test_ds=spark.createDataFrame(test_data, test_schema)\n",
    "test_ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22584af75b54fb47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T09:44:50.532496192Z",
     "start_time": "2023-12-18T09:44:42.192457043Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+----+----+\n",
      "|Id_1|Id_2|Year|Me_1|Me_2|\n",
      "+----+----+----+----+----+\n",
      "|   A|  XX|2000|   3| 1.0|\n",
      "|   A|  XX|2001|   4| 9.0|\n",
      "|   A|  XX|2002|   7| 5.0|\n",
      "|   A|  XX|2003|   6| 8.0|\n",
      "|   A|  YY|2000|   9| 3.0|\n",
      "|   A|  YY|2001|   5| 4.0|\n",
      "|   A|  YY|2002|  10| 2.0|\n",
      "|   A|  YY|2003|   5| 7.0|\n",
      "+----+----+----+----+----+\n"
     ]
    }
   ],
   "source": [
    "data1=[(\"A\", \"XX\", 2000, 3, 1.0),\n",
    "    (\"A\", \"XX\", 2001, 4, 9.0),\n",
    "    (\"A\", \"XX\", 2002, 7, 5.0),\n",
    "    (\"A\", \"XX\", 2003, 6, 8.0),\n",
    "    (\"A\", \"YY\", 2000, 9, 3.0),\n",
    "    (\"A\", \"YY\", 2001, 5, 4.0),\n",
    "    (\"A\", \"YY\", 2002, 10, 2.0),\n",
    "    (\"A\", \"YY\", 2003, 5, 7.0)]\n",
    "\n",
    "schema1=StructType([StructField(\"Id_1\",StringType(),True),\n",
    "                   StructField(\"Id_2\",StringType(),True),\n",
    "                   StructField(\"Year\",IntegerType(),True),\n",
    "                   StructField(\"Me_1\",IntegerType(),True),\n",
    "                   StructField(\"Me_2\",DoubleType(),True)])\n",
    "\n",
    "ds1=spark.createDataFrame(data1, schema1)\n",
    "ds1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea8d58fcf90ce0cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T09:48:43.200432960Z",
     "start_time": "2023-12-18T09:48:42.575996579Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+----+----+\n",
      "|Id_1|Id_2|Year|Me_1|Me_2|\n",
      "+----+----+----+----+----+\n",
      "|   A|  XX|1993|   3| 1.0|\n",
      "|   A|  XX|1994|   4| 9.0|\n",
      "|   A|  XX|1995|   7| 5.0|\n",
      "|   A|  XX|1996|   6| 8.0|\n",
      "|   A|  YY|1993|   9| 3.0|\n",
      "|   A|  YY|1994|   5| 4.0|\n",
      "|   A|  YY|1995|  10| 2.0|\n",
      "|   A|  YY|1996|   2| 7.0|\n",
      "+----+----+----+----+----+\n"
     ]
    }
   ],
   "source": [
    "data2=[(\"A\", \"XX\", 1993, 3, 1.0),\n",
    "    (\"A\", \"XX\", 1994, 4, 9.0),\n",
    "    (\"A\", \"XX\", 1995, 7, 5.0),\n",
    "    (\"A\", \"XX\", 1996, 6, 8.0),\n",
    "    (\"A\", \"YY\", 1993, 9, 3.0),\n",
    "    (\"A\", \"YY\", 1994, 5, 4.0),\n",
    "    (\"A\", \"YY\", 1995, 10, 2.0),\n",
    "    (\"A\", \"YY\", 1996, 2, 7.0)]\n",
    "\n",
    "\n",
    "schema2=StructType([StructField(\"Id_1\",StringType(),True),\n",
    "                   StructField(\"Id_2\",StringType(),True),\n",
    "                   StructField(\"Year\",IntegerType(),True),\n",
    "                   StructField(\"Me_1\",IntegerType(),True),\n",
    "                   StructField(\"Me_2\",DoubleType(),True)])\n",
    "\n",
    "ds2=spark.createDataFrame(data2, schema2)\n",
    "ds2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51e5ba5e3d3bcca",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 1. Fist function\n",
    "\n",
    "### 1.1 Fist with range between\n",
    "\n",
    "**Range between**: It defines a sliding window as a numerical offset relative to the current data point (according to the orderBy clause). In another word, it defines the `frame boundaries based on the values of the order column in the partition that fall within a specified range relative to the current row's value`. \n",
    "\n",
    "\n",
    "With the below example, the frame is ordered by the value of Column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a47f246e116d4ad4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T14:03:58.678555719Z",
     "start_time": "2023-12-18T14:03:58.088292026Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----+----+----+----------+----------+\n",
      "|Row_id|Id_2|Year|Me_1|Me_2|first_Me_1|first_Me_2|\n",
      "+------+----+----+----+----+----------+----------+\n",
      "|     1|  XX|1993|   3| 1.0|         3|       1.0|\n",
      "|     2|  XX|1994|   4| 9.0|         3|       1.0|\n",
      "|     3|  XX|1995|   7| 5.0|         4|       9.0|\n",
      "+------+----+----+----+----+----------+----------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "win_with_custom_range = Window.partitionBy(\"Id_2\").orderBy(\"Year\").rangeBetween(-1,1)\n",
    "res = test_ds.withColumn(\"first_Me_1\", first(col(\"Me_1\")).over(win_with_custom_range))\\\n",
    "         .withColumn(\"first_Me_2\", first(col(\"Me_2\")).over(win_with_custom_range))\n",
    "print(res.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627a3927df3839a1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "```\n",
    "# VTL syntax: \n",
    "\n",
    "res := first_value ( ds2 over ( partition by Id_1 order by Year range between -1 preceding and 1 following) );\n",
    "\n",
    "# pyspark syntax: \n",
    "win_with_custom_range = Window.partitionBy(\"Id_1\").orderBy(\"Year\").rangeBetween(-1,1)\n",
    "res = ds2.withColumn(\"first_Me_1\", first(col(\"Me_1\")).over(win_with_custom_range))\\\n",
    "         .withColumn(\"first_Me_2\", first(col(\"Me_2\")).over(win_with_custom_range))\n",
    "\n",
    "# input\n",
    "+----+----+----+----+----+\n",
    "|Id_1|Id_2|Year|Me_1|Me_2|\n",
    "+----+----+----+----+----+\n",
    "|   A|  XX|1993|   3| 1.0|\n",
    "|   A|  XX|1994|   4| 9.0|\n",
    "|   A|  XX|1995|   7| 5.0|\n",
    "|   A|  XX|1996|   6| 8.0|\n",
    "|   A|  YY|1993|   9| 3.0|\n",
    "|   A|  YY|1994|   5| 4.0|\n",
    "|   A|  YY|1995|  10| 2.0|\n",
    "|   A|  YY|1996|   2| 7.0|\n",
    "+----+----+----+----+----+\n",
    "\n",
    "# output\n",
    "+----+----+----+----+----+----------+----------+\n",
    "|Id_1|Id_2|Year|Me_1|Me_2|first_Me_1|first_Me_2|\n",
    "+----+----+----+----+----+----------+----------+\n",
    "|   A|  XX|1993|   3| 1.0|         3|       1.0|\n",
    "|   A|  YY|1993|   9| 3.0|         3|       1.0|\n",
    "|   A|  XX|1994|   4| 9.0|         3|       1.0|\n",
    "|   A|  YY|1994|   5| 4.0|         3|       1.0|\n",
    "|   A|  XX|1995|   7| 5.0|         4|       9.0|\n",
    "|   A|  YY|1995|  10| 2.0|         4|       9.0|\n",
    "|   A|  XX|1996|   6| 8.0|         7|       5.0|\n",
    "|   A|  YY|1996|   2| 7.0|         7|       5.0|\n",
    "+----+----+----+----+----+----------+----------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1c7ecf37ae50803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T12:52:30.723327464Z",
     "start_time": "2023-12-18T12:52:30.604622242Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# win_with_custom_range = Window.partitionBy(\"Id_1\").orderBy(\"Year\").rangeBetween(-1,1)\n",
    "win_with_custom_range = Window.partitionBy(\"Id_1\",\"Id_2\").orderBy(\"Year\").rangeBetween(-1,1)\n",
    "res = ds2.withColumn(\"first_Me_1\", first(col(\"Me_1\")).over(win_with_custom_range))\\\n",
    "         .withColumn(\"first_Me_2\", first(col(\"Me_2\")).over(win_with_custom_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6f24dbc95c6f67f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T13:17:40.020989997Z",
     "start_time": "2023-12-18T13:17:39.352182069Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+----+----+----------+----------+\n",
      "|Id_1|Id_2|Year|Me_1|Me_2|first_Me_1|first_Me_2|\n",
      "+----+----+----+----+----+----------+----------+\n",
      "|   A|  XX|1993|   3| 1.0|         3|       1.0|\n",
      "|   A|  XX|1994|   4| 9.0|         3|       1.0|\n",
      "|   A|  XX|1995|   7| 5.0|         4|       9.0|\n",
      "|   A|  XX|1996|   6| 8.0|         7|       5.0|\n",
      "|   A|  YY|1993|   9| 3.0|         9|       3.0|\n",
      "|   A|  YY|1994|   5| 4.0|         9|       3.0|\n",
      "|   A|  YY|1995|  10| 2.0|         5|       4.0|\n",
      "|   A|  YY|1996|   2| 7.0|        10|       2.0|\n",
      "+----+----+----+----+----+----------+----------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(res.show(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6a34548fbe2af9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 1.2 Fist with data points(rows) between\n",
    "\n",
    "**data points between**: defines a sliding window using a specified number of preceding and following data points relative to the current data point (according to the orderBy clause). In another word, it defines the frame boundaries based on `the number of rows before and after the current row` within the partition.\n",
    "\n",
    "For example if I have 3 rows in a dataset \n",
    "```\n",
    "+----+----+----+----+----+\n",
    "|Row_id|Id_2|Year|Me_1|Me_2|\n",
    "+----+----+----+----+----+\n",
    "|   1|  XX|1993|   3| 1.0|\n",
    "|   2|  XX|1994|   4| 9.0|\n",
    "|   3|  XX|1995|   7| 5.0|\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "898db59d1861ed75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T13:29:04.212431183Z",
     "start_time": "2023-12-18T13:29:03.709515796Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----+----+----+\n",
      "|Row_id|Id_2|Year|Me_1|Me_2|\n",
      "+------+----+----+----+----+\n",
      "|     1|  XX|1993|   3| 1.0|\n",
      "|     2|  XX|1994|   4| 9.0|\n",
      "|     3|  XX|1995|   7| 5.0|\n",
      "+------+----+----+----+----+\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb29bbe538709940",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T13:30:29.838912977Z",
     "start_time": "2023-12-18T13:30:28.651062254Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----+----+----+----------+----------+\n",
      "|Row_id|Id_2|Year|Me_1|Me_2|first_Me_1|first_Me_2|\n",
      "+------+----+----+----+----+----------+----------+\n",
      "|     1|  XX|1993|   3| 1.0|         3|       1.0|\n",
      "|     2|  XX|1994|   4| 9.0|         3|       1.0|\n",
      "|     3|  XX|1995|   7| 5.0|         4|       9.0|\n",
      "+------+----+----+----+----+----------+----------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "win_with_custom_range = Window.partitionBy(\"Id_2\").orderBy(\"Year\").rowsBetween(-1,1)\n",
    "res = test_ds.withColumn(\"first_Me_1\", first(col(\"Me_1\")).over(win_with_custom_range))\\\n",
    "         .withColumn(\"first_Me_2\", first(col(\"Me_2\")).over(win_with_custom_range))\n",
    "print(res.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38fd565f8f60f8bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T11:03:52.693135232Z",
     "start_time": "2023-12-18T11:03:52.581644365Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "win_with_custom_range = Window.partitionBy(\"Id_1\",\"Id_2\").orderBy(\"Year\").rowsBetween(-2,2)\n",
    "res = ds2.withColumn(\"first_Me_1\", first(col(\"Me_1\")).over(win_with_custom_range))\\\n",
    "         .withColumn(\"first_Me_2\", first(col(\"Me_2\")).over(win_with_custom_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc0bd158a2689a50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-18T11:03:56.148601380Z",
     "start_time": "2023-12-18T11:03:54.979258843Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+----+----+----------+----------+\n",
      "|Id_1|Id_2|Year|Me_1|Me_2|first_Me_1|first_Me_2|\n",
      "+----+----+----+----+----+----------+----------+\n",
      "|   A|  XX|1993|   3| 1.0|         3|       1.0|\n",
      "|   A|  XX|1994|   4| 9.0|         3|       1.0|\n",
      "|   A|  XX|1995|   7| 5.0|         3|       1.0|\n",
      "|   A|  XX|1996|   6| 8.0|         4|       9.0|\n",
      "|   A|  YY|1993|   9| 3.0|         9|       3.0|\n",
      "|   A|  YY|1994|   5| 4.0|         9|       3.0|\n",
      "|   A|  YY|1995|  10| 2.0|         9|       3.0|\n",
      "|   A|  YY|1996|   2| 7.0|         5|       4.0|\n",
      "+----+----+----+----+----+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "res.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68aeb4b72258353",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
