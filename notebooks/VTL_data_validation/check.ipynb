{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# VTL Check\n",
    "\n",
    "The original doc can be found at **line 6575 of VTL-2.0-Reference-Manual**\n",
    "## Syntax\n",
    "\n",
    "```text\n",
    "check ( op { errorcode errorcode } { errorlevel errorlevel } { imbalance imbalance } { output } )\n",
    "  - output ::= invalid | all\n",
    "\n",
    "```\n",
    "\n",
    "- **op**: a boolean Data Set (a boolean condition expressed on one or more Data Sets)\n",
    "- **errorcode**: the error code to be produced when the condition evaluates to FALSE. It must be a valid value of the `errorcode_vd` Value Domain (or string if the `errorcode_vd` Value Domain is not found). It can be a Data Set or a scalar. If not specified then `errorcode` is NULL.\n",
    "- **errorlevel**: the error level to be produced when the condition evaluates to FALSE. It must be a valid value of the `errorlevel_vd` Value Domain (or integer if the `errorcode_vd` Value Domain is not found). It can be a Data Set or a scalar. If not specified then `errorlevel` is NULL\n",
    "- **imbalance**: the imbalance to be computed. `imbalance` is a numeric mono-measure Data Set with the same 6587 Identifiers of op. If not specified then imbalance is NULL.\n",
    "- **output**: specifies which Data Points are returned to the resulting Data Set:\n",
    "     - **invalid**: returns the Data Points of `op` for which the condition evaluates to FALSE\n",
    "     - **all**: returns all Data Points of op\n",
    "     - If not specified then output is `all`.\n",
    "\n",
    "## Example\n",
    "\n",
    "Given the Data Set DS_1:\n",
    "```text\n",
    "Id_1,Id_2,Me_1\n",
    "2010,I,1\n",
    "2011,I,2\n",
    "2012,I,10\n",
    "2013,I,4\n",
    "2014,I,5\n",
    "2015,I,6\n",
    "2010,D,25\n",
    "2011,D,35\n",
    "2012,D,45\n",
    "2013,D,55\n",
    "2014,D,50\n",
    "2015,D,75\n",
    "```\n",
    "\n",
    "Given the Data Set DS_2:\n",
    "```text\n",
    "Id_1,Id_2,Me_1\n",
    "2010,I,9\n",
    "2011,I,2\n",
    "2012,I,10\n",
    "2013,I,7\n",
    "2014,I,5\n",
    "2015,I,6\n",
    "2010,D,50\n",
    "2011,D,35\n",
    "2012,D,40\n",
    "2013,D,55\n",
    "2014,D,65\n",
    "2015,D,75\n",
    "```\n",
    "`DS_r := check ( DS1 >= DS2 imbalance DS1 - DS2 )` results in:\n",
    "\n",
    "```text\n",
    "Id_1 Id_2 bool_var imbalance errorcode errorlevel\n",
    "2010 I FALSE -8 NULL NULL\n",
    "2011 I TRUE 0 NULL NULL\n",
    "2012 I TRUE 0 NULL NULL\n",
    "2013 I FALSE -3 NULL NULL\n",
    "2014 I TRUE 0 NULL NULL\n",
    "2015 I TRUE 0 NULL NULL\n",
    "2010 D FALSE -25 NULL NULL\n",
    "2011 D TRUE 0 NULL NULL\n",
    "2012 D TRUE 5 NULL NULL\n",
    "2013 D TRUE 0 NULL NULL\n",
    "2014 D FALSE -15 NULL NULL\n",
    "2015 D TRUE 0 NULL NULL\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession,DataFrame\n",
    "\n",
    "import os\n",
    "from pyspark.sql.functions import col, lit, when\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/13 09:28:32 WARN Utils: Your hostname, pengfei-Virtual-Machine resolves to a loopback address: 127.0.1.1; using 10.50.2.80 instead (on interface eth0)\n",
      "22/10/13 09:28:32 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/13 09:28:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "local = True\n",
    "\n",
    "if local:\n",
    "    spark = SparkSession.builder \\\n",
    "        .master(\"local[4]\") \\\n",
    "        .appName(\"VTLValidation-check\")\\\n",
    "        .getOrCreate()\n",
    "else:\n",
    "    spark = SparkSession.builder\\\n",
    "        .master(\"k8s://https://kubernetes.default.svc:443\") \\\n",
    "        .appName(\"VTLValidation-check\")\\\n",
    "        .config(\"spark.kubernetes.container.image\", \"inseefrlab/jupyter-datascience:py3.9.7-spark3.2.0\")\\\n",
    "        .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\", os.environ['KUBERNETES_SERVICE_ACCOUNT'])\\\n",
    "        .config(\"spark.executor.instances\", \"4\")\\\n",
    "        .config(\"spark.executor.memory\", \"4g\")\\\n",
    "        .config(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE'])\\\n",
    "        .getOrCreate()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "root_path=\"../../data\"\n",
    "data_path1=f\"{root_path}/check_ds1.csv\"\n",
    "data_path2=f\"{root_path}/check_ds2.csv\"\n",
    "df1=spark.read.csv(data_path1, header=True,inferSchema=True)\n",
    "df2=spark.read.csv(data_path2, header=True,inferSchema=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|Id_1|Id_2|Me_1|\n",
      "+----+----+----+\n",
      "|2010|   I|   1|\n",
      "|2011|   I|   2|\n",
      "|2012|   I|  10|\n",
      "|2013|   I|   4|\n",
      "|2014|   I|   5|\n",
      "|2015|   I|   6|\n",
      "|2010|   D|  25|\n",
      "|2011|   D|  35|\n",
      "|2012|   D|  45|\n",
      "|2013|   D|  55|\n",
      "|2014|   D|  50|\n",
      "|2015|   D|  75|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|Id_1|Id_2|Me_1|\n",
      "+----+----+----+\n",
      "|2010|   I|   9|\n",
      "|2011|   I|   2|\n",
      "|2012|   I|  10|\n",
      "|2013|   I|   7|\n",
      "|2014|   I|   5|\n",
      "|2015|   I|   6|\n",
      "|2010|   D|  50|\n",
      "|2011|   D|  35|\n",
      "|2012|   D|  40|\n",
      "|2013|   D|  55|\n",
      "|2014|   D|  65|\n",
      "|2015|   D|  75|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Inner Join on the two data frame\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "target_col_name=\"Me_1\"\n",
    "clean_col_name1=f\"df1_{target_col_name}\"\n",
    "clean_col_name2=f\"df2_{target_col_name}\"\n",
    "df1_clean=df1.withColumnRenamed(target_col_name,clean_col_name1)\n",
    "df2_clean=df2.withColumnRenamed(target_col_name,clean_col_name2)\n",
    "df_join=df1_clean.join(df2_clean, [\"Id_1\",\"Id_2\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+--------+--------+\n",
      "|Id_1|Id_2|df1_Me_1|df2_Me_1|\n",
      "+----+----+--------+--------+\n",
      "|2010|   I|       1|       9|\n",
      "|2011|   I|       2|       2|\n",
      "|2012|   I|      10|      10|\n",
      "|2013|   I|       4|       7|\n",
      "|2014|   I|       5|       5|\n",
      "|2015|   I|       6|       6|\n",
      "|2010|   D|      25|      50|\n",
      "|2011|   D|      35|      35|\n",
      "|2012|   D|      45|      40|\n",
      "|2013|   D|      55|      55|\n",
      "|2014|   D|      50|      65|\n",
      "|2015|   D|      75|      75|\n",
      "+----+----+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Apply check rules and imbalance rule"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "df_part=df_join.withColumn(\"imbalance\",col(clean_col_name1)-col(clean_col_name2))\\\n",
    "    .withColumn(\"bool_var\",when((col(clean_col_name1) >= col(clean_col_name2)),True).otherwise(False))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Apply the error code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "error_code=\"Ds1 is not valid\"\n",
    "error_level=\"6\"\n",
    "\n",
    "df_resu=df_part.withColumn(\"error_code\",when(col(\"bool_var\")==False,error_code).otherwise(\"null\")) \\\n",
    "           .withColumn(\"error_level\",when(col(\"bool_var\")==False,error_level).otherwise(\"null\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+--------+--------+---------+--------+----------------+-----------+\n",
      "|Id_1|Id_2|df1_Me_1|df2_Me_1|imbalance|bool_var|      error_code|error_level|\n",
      "+----+----+--------+--------+---------+--------+----------------+-----------+\n",
      "|2010|   I|       1|       9|       -8|   false|Ds1 is not valid|          6|\n",
      "|2011|   I|       2|       2|        0|    true|            null|       null|\n",
      "|2012|   I|      10|      10|        0|    true|            null|       null|\n",
      "|2013|   I|       4|       7|       -3|   false|Ds1 is not valid|          6|\n",
      "|2014|   I|       5|       5|        0|    true|            null|       null|\n",
      "|2015|   I|       6|       6|        0|    true|            null|       null|\n",
      "|2010|   D|      25|      50|      -25|   false|Ds1 is not valid|          6|\n",
      "|2011|   D|      35|      35|        0|    true|            null|       null|\n",
      "|2012|   D|      45|      40|        5|    true|            null|       null|\n",
      "|2013|   D|      55|      55|        0|    true|            null|       null|\n",
      "|2014|   D|      50|      65|      -15|   false|Ds1 is not valid|          6|\n",
      "|2015|   D|      75|      75|        0|    true|            null|       null|\n",
      "+----+----+--------+--------+---------+--------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_resu.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def check_01(df1,df2,option):\n",
    "    error_code=\"Ds1 is not valid\"\n",
    "    error_level=\"6\"\n",
    "    target_col_name=\"Me_1\"\n",
    "    clean_col_name1=f\"df1_{target_col_name}\"\n",
    "    clean_col_name2=f\"df2_{target_col_name}\"\n",
    "    df1_clean=df1.withColumnRenamed(target_col_name,clean_col_name1)\n",
    "    df2_clean=df2.withColumnRenamed(target_col_name,clean_col_name2)\n",
    "    df_join=df1_clean.join(df2_clean, [\"Id_1\",\"Id_2\"])\n",
    "\n",
    "\n",
    "    df_part=df_join.withColumn(\"imbalance\",col(clean_col_name1)-col(clean_col_name2))\\\n",
    "    .withColumn(\"bool_var\",when((col(clean_col_name1) >= col(clean_col_name2)),True).otherwise(False))\n",
    "    df_all=df_part.withColumn(\"error_code\",when(col(\"bool_var\")==False,error_code).otherwise(\"null\")) \\\n",
    "           .withColumn(\"error_level\",when(col(\"bool_var\")==False,error_level).otherwise(\"null\"))\n",
    "    if option==\"all\":\n",
    "        return df_all\n",
    "    elif option==\"invalid\":\n",
    "        return df_all.filter(col(\"bool_var\")==False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+--------+--------+---------+--------+----------------+-----------+\n",
      "|Id_1|Id_2|df1_Me_1|df2_Me_1|imbalance|bool_var|      error_code|error_level|\n",
      "+----+----+--------+--------+---------+--------+----------------+-----------+\n",
      "|2010|   I|       1|       9|       -8|   false|Ds1 is not valid|          6|\n",
      "|2011|   I|       2|       2|        0|    true|            null|       null|\n",
      "|2012|   I|      10|      10|        0|    true|            null|       null|\n",
      "|2013|   I|       4|       7|       -3|   false|Ds1 is not valid|          6|\n",
      "|2014|   I|       5|       5|        0|    true|            null|       null|\n",
      "|2015|   I|       6|       6|        0|    true|            null|       null|\n",
      "|2010|   D|      25|      50|      -25|   false|Ds1 is not valid|          6|\n",
      "|2011|   D|      35|      35|        0|    true|            null|       null|\n",
      "|2012|   D|      45|      40|        5|    true|            null|       null|\n",
      "|2013|   D|      55|      55|        0|    true|            null|       null|\n",
      "|2014|   D|      50|      65|      -15|   false|Ds1 is not valid|          6|\n",
      "|2015|   D|      75|      75|        0|    true|            null|       null|\n",
      "+----+----+--------+--------+---------+--------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_all=check_01(df1,df2,\"all\")\n",
    "result_all.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+--------+--------+---------+--------+----------------+-----------+\n",
      "|Id_1|Id_2|df1_Me_1|df2_Me_1|imbalance|bool_var|      error_code|error_level|\n",
      "+----+----+--------+--------+---------+--------+----------------+-----------+\n",
      "|2010|   I|       1|       9|       -8|   false|Ds1 is not valid|          6|\n",
      "|2013|   I|       4|       7|       -3|   false|Ds1 is not valid|          6|\n",
      "|2010|   D|      25|      50|      -25|   false|Ds1 is not valid|          6|\n",
      "|2014|   D|      50|      65|      -15|   false|Ds1 is not valid|          6|\n",
      "+----+----+--------+--------+---------+--------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_invalid=check_01(df1,df2,\"invalid\")\n",
    "result_invalid.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
