{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# VTL Check\n",
    "\n",
    "The original doc can be found at **line 6575 of VTL-2.0-Reference-Manual**\n",
    "## Syntax\n",
    "\n",
    "```text\n",
    "check ( op { errorcode errorcode } { errorlevel errorlevel } { imbalance imbalance } { output } )\n",
    "  - output ::= invalid | all\n",
    "\n",
    "```\n",
    "\n",
    "- **op**: a boolean Data Set (a boolean condition expressed on one or more Data Sets)\n",
    "- **dpr**: the Data Point Ruleset to be used 6327\n",
    "- **listComp**: if `dpr` is defined on Value Domains then `listComp` is the list of Components of `op` to be associated (in positional order) to the conditioning Value Domains defined in `dpr`. If `dpr` is defined on Variables then listComp is the list of Components of op to be associated (in positional order) to the conditioning Variables defined in dpr (for documentation purposes).\n",
    "- **comp**: Component of `op`\n",
    "- **output**: specifies the Data Points and the Measures of the resulting Data Set:\n",
    "     - **invalid**: the resulting Data Set contains a Data Point for each Data Point of `op` and  each Rule in `dpr` that evaluates to `FALSE` on that Data Point. The resulting Data Set has the Measures of op.\n",
    "     - **all**: the resulting Data Set contains a data point for each Data Point of `op` and each Rule in `dpr`. The resulting Data Set has the boolean Measure bool_var.\n",
    "     - **all_measures**: the resulting Data Set contains a Data Point for each Data Point of `op` and each Rule in `dpr`. The resulting dataset has the Measures of `op` and the  boolean Measure bool_var.\n",
    "     - If not specified then output is assumed to be invalid. See the Behaviour for further details.\n",
    "\n",
    "## Example\n",
    "\n",
    "Step 1. Define `dpr`\n",
    "\n",
    "```text\n",
    "define datapoint ruleset dpr1 ( variable Id_3, Me_1 ) is\n",
    "        # the rule of dpr1_1\n",
    "        when Id_3 = “CREDIT” then Me_1 >= 0 errorcode “Bad credit” errorlevel 5;\n",
    "        # the rule of dpr1_2\n",
    "        when Id_3 = “DEBIT” then Me_1 >= 0 errorcode “Bad debit” errorlevel 6\n",
    "end datapoint ruleset\n",
    "```\n",
    "\n",
    "Step 2. Apply `dpr` on `ds`\n",
    "\n",
    "Given the Data Set DS_1:\n",
    "```text\n",
    "Id_1,Id_2,Me_1\n",
    "2010,I,1\n",
    "2011,I,2\n",
    "2012,I,10\n",
    "2013,I,4\n",
    "2014,I,5\n",
    "2015,I,6\n",
    "2010,D,25\n",
    "2011,D,35\n",
    "2012,D,45\n",
    "2013,D,55\n",
    "2014,D,50\n",
    "2015,D,75\n",
    "```\n",
    "\n",
    "Given the Data Set DS_2:\n",
    "```text\n",
    "Id_1,Id_2,Me_1\n",
    "2010,I,9\n",
    "2011,I,2\n",
    "2012,I,10\n",
    "2013,I,7\n",
    "2014,I,5\n",
    "2015,I,6\n",
    "2010,D,50\n",
    "2011,D,35\n",
    "2012,D,40\n",
    "2013,D,55\n",
    "2014,D,65\n",
    "2015,D,75\n",
    "```\n",
    "`DS_r := check ( DS1 >= DS2 imbalance DS1 - DS2 )` results in:\n",
    "\n",
    "```text\n",
    "Id_1 Id_2 bool_var imbalance errorcode errorlevel\n",
    "2010 I FALSE -8 NULL NULL\n",
    "2011 I TRUE 0 NULL NULL\n",
    "2012 I TRUE 0 NULL NULL\n",
    "2013 I FALSE -3 NULL NULL\n",
    "2014 I TRUE 0 NULL NULL\n",
    "2015 I TRUE 0 NULL NULL\n",
    "2010 D FALSE -25 NULL NULL\n",
    "2011 D TRUE 0 NULL NULL\n",
    "2012 D TRUE 5 NULL NULL\n",
    "2013 D TRUE 0 NULL NULL\n",
    "2014 D FALSE -15 NULL NULL\n",
    "2015 D TRUE 0 NULL NULL\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession,DataFrame\n",
    "\n",
    "import os\n",
    "from pyspark.sql.functions import col, lit, when\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/13 09:28:32 WARN Utils: Your hostname, pengfei-Virtual-Machine resolves to a loopback address: 127.0.1.1; using 10.50.2.80 instead (on interface eth0)\n",
      "22/10/13 09:28:32 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/13 09:28:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "local = True\n",
    "\n",
    "if local:\n",
    "    spark = SparkSession.builder \\\n",
    "        .master(\"local[4]\") \\\n",
    "        .appName(\"VTLValidation-check\")\\\n",
    "        .getOrCreate()\n",
    "else:\n",
    "    spark = SparkSession.builder\\\n",
    "        .master(\"k8s://https://kubernetes.default.svc:443\") \\\n",
    "        .appName(\"VTLValidation-check\")\\\n",
    "        .config(\"spark.kubernetes.container.image\", \"inseefrlab/jupyter-datascience:py3.9.7-spark3.2.0\")\\\n",
    "        .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\", os.environ['KUBERNETES_SERVICE_ACCOUNT'])\\\n",
    "        .config(\"spark.executor.instances\", \"4\")\\\n",
    "        .config(\"spark.executor.memory\", \"4g\")\\\n",
    "        .config(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE'])\\\n",
    "        .getOrCreate()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "root_path=\"../../data\"\n",
    "data_path1=f\"{root_path}/check_ds1.csv\"\n",
    "data_path2=f\"{root_path}/check_ds2.csv\"\n",
    "df1=spark.read.csv(data_path1, header=True,inferSchema=True)\n",
    "df2=spark.read.csv(data_path2, header=True,inferSchema=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|Id_1|Id_2|Me_1|\n",
      "+----+----+----+\n",
      "|2010|   I|   1|\n",
      "|2011|   I|   2|\n",
      "|2012|   I|  10|\n",
      "|2013|   I|   4|\n",
      "|2014|   I|   5|\n",
      "|2015|   I|   6|\n",
      "|2010|   D|  25|\n",
      "|2011|   D|  35|\n",
      "|2012|   D|  45|\n",
      "|2013|   D|  55|\n",
      "|2014|   D|  50|\n",
      "|2015|   D|  75|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|Id_1|Id_2|Me_1|\n",
      "+----+----+----+\n",
      "|2010|   I|   9|\n",
      "|2011|   I|   2|\n",
      "|2012|   I|  10|\n",
      "|2013|   I|   7|\n",
      "|2014|   I|   5|\n",
      "|2015|   I|   6|\n",
      "|2010|   D|  50|\n",
      "|2011|   D|  35|\n",
      "|2012|   D|  40|\n",
      "|2013|   D|  55|\n",
      "|2014|   D|  65|\n",
      "|2015|   D|  75|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Inner Join on the two data frame\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "target_col_name=\"Me_1\"\n",
    "clean_col_name1=f\"df1_{target_col_name}\"\n",
    "clean_col_name2=f\"df2_{target_col_name}\"\n",
    "df1_clean=df1.withColumnRenamed(target_col_name,clean_col_name1)\n",
    "df2_clean=df2.withColumnRenamed(target_col_name,clean_col_name2)\n",
    "df_join=df1_clean.join(df2_clean, [\"Id_1\",\"Id_2\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+--------+--------+\n",
      "|Id_1|Id_2|df1_Me_1|df2_Me_1|\n",
      "+----+----+--------+--------+\n",
      "|2010|   I|       1|       9|\n",
      "|2011|   I|       2|       2|\n",
      "|2012|   I|      10|      10|\n",
      "|2013|   I|       4|       7|\n",
      "|2014|   I|       5|       5|\n",
      "|2015|   I|       6|       6|\n",
      "|2010|   D|      25|      50|\n",
      "|2011|   D|      35|      35|\n",
      "|2012|   D|      45|      40|\n",
      "|2013|   D|      55|      55|\n",
      "|2014|   D|      50|      65|\n",
      "|2015|   D|      75|      75|\n",
      "+----+----+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Apply check rules and imbalance rule"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "df_part=df_join.withColumn(\"imbalance\",col(clean_col_name1)-col(clean_col_name2))\\\n",
    "    .withColumn(\"bool_var\",when((col(clean_col_name1) >= col(clean_col_name2)),True).otherwise(False))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Apply the error code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "error_code=\"Ds1 is not valid\"\n",
    "error_level=\"6\"\n",
    "\n",
    "df_resu=df_part.withColumn(\"error_code\",when(col(\"bool_var\")==False,error_code).otherwise(\"null\")) \\\n",
    "           .withColumn(\"error_level\",when(col(\"bool_var\")==False,error_level).otherwise(\"null\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+--------+--------+---------+--------+----------------+-----------+\n",
      "|Id_1|Id_2|df1_Me_1|df2_Me_1|imbalance|bool_var|      error_code|error_level|\n",
      "+----+----+--------+--------+---------+--------+----------------+-----------+\n",
      "|2010|   I|       1|       9|       -8|   false|Ds1 is not valid|          6|\n",
      "|2011|   I|       2|       2|        0|    true|            null|       null|\n",
      "|2012|   I|      10|      10|        0|    true|            null|       null|\n",
      "|2013|   I|       4|       7|       -3|   false|Ds1 is not valid|          6|\n",
      "|2014|   I|       5|       5|        0|    true|            null|       null|\n",
      "|2015|   I|       6|       6|        0|    true|            null|       null|\n",
      "|2010|   D|      25|      50|      -25|   false|Ds1 is not valid|          6|\n",
      "|2011|   D|      35|      35|        0|    true|            null|       null|\n",
      "|2012|   D|      45|      40|        5|    true|            null|       null|\n",
      "|2013|   D|      55|      55|        0|    true|            null|       null|\n",
      "|2014|   D|      50|      65|      -15|   false|Ds1 is not valid|          6|\n",
      "|2015|   D|      75|      75|        0|    true|            null|       null|\n",
      "+----+----+--------+--------+---------+--------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_resu.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
