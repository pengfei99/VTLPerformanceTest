{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# VTL Check hierarchy\n",
    "\n",
    "The original doc can be found at **line 6399 of VTL-2.0-Reference-Manual**\n",
    "\n",
    "## Syntax\n",
    "\n",
    "```text\n",
    "check_hierarchy ( op , hr { condition condComp { , condComp }* } { rule ruleComp }\n",
    "{ mode } { input } { output } )\n",
    "  - mode ::= non_null | non_zero | partial_null | partial_zero | always_null | always_zero\n",
    "  - input ::= dataset | dataset_priority\n",
    "  - output ::= invalid | all | all_measures\n",
    "\n",
    "```\n",
    "\n",
    "- **op**: the Data Set to be checked\n",
    "- **hr**: the hierarchical Ruleset to be used\n",
    "- **condComp**: `condComp` is a Component of `op` to be associated (in positional order) to the conditioning Value Domains or Variables defined in `hr` (if any).\n",
    "- **ruleComp**: Component of `op`\n",
    "- **mode**: this parameter specifies how to treat the possible missing Data Points corresponding to the Code Items in the left and right sides of the rules and which Data Points are produced in output. The meaning of the possible values of the parameter is explained below.\n",
    "- **output**: specifies the Data Points and the Measures of the resulting Data Set:\n",
    "     - **invalid**: the resulting Data Set contains a Data Point for each Data Point of `op` and  each Rule in `dpr` that evaluates to `FALSE` on that Data Point. The resulting Data Set has the Measures of op.\n",
    "     - **all**: the resulting Data Set contains a data point for each Data Point of `op` and each Rule in `dpr`. The resulting Data Set has the boolean Measure bool_var.\n",
    "     - **all_measures**: the resulting Data Set contains a Data Point for each Data Point of `op` and each Rule in `dpr`. The resulting dataset has the Measures of `op` and the  boolean Measure bool_var.\n",
    "     - If not specified then output is assumed to be invalid. See the Behaviour for further details.\n",
    "\n",
    "## Example\n",
    "\n",
    "1. Define hierarchical ruleset.\n",
    "\n",
    "```text\n",
    "define hierarchical ruleset HR_1 ( valuedomain rule VD_1 ) is\n",
    "   R010 : A = J + K + L errorcode Bad_val errorlevel 5;\n",
    "   R020 : B = M + N + O errorcode Bad_val errorlevel 5;\n",
    "   R070 : G = B + C errorcode Bad_val errorlevel 1\n",
    "```\n",
    "\n",
    "Given a dataset ds_1:\n",
    "\n",
    "```text\n",
    "Id_1,Id_2,Me_1\n",
    "2010,A,5\n",
    "2010,B,11\n",
    "2010,C,0\n",
    "2010,G,19\n",
    "2010,H,NULL\n",
    "2010,I,14\n",
    "2010,M,2\n",
    "2010,N,5\n",
    "2010,O,4\n",
    "2010,P,7\n",
    "2010,Q,-7\n",
    "2010,S,3\n",
    "2010,T,9\n",
    "2010,U,NULL\n",
    "2010,V,6\n",
    "```\n",
    "\n",
    "The output should be:\n",
    "\n",
    "```text\n",
    "\n",
    "Id_1,Id_2,ruleid,Bool_var,imbalance,errorcode,errorlevel\n",
    "2010,A,R010,NULL,NULL,NULL,NULL\n",
    "2010,B,R020,TRUE,0,NULL,NULL\n",
    "2010,G,R070,FALSE,8,Bad_val,1\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession,DataFrame\n",
    "\n",
    "import os\n",
    "from pyspark.sql.functions import col, lit, when\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "local = True\n",
    "\n",
    "if local:\n",
    "    spark = SparkSession.builder \\\n",
    "        .master(\"local[4]\") \\\n",
    "        .appName(\"VTLValidation_check_hierarchy\")\\\n",
    "        .getOrCreate()\n",
    "else:\n",
    "    spark = SparkSession.builder\\\n",
    "        .master(\"k8s://https://kubernetes.default.svc:443\") \\\n",
    "        .appName(\"VTLValidation_check_hierarchy\")\\\n",
    "        .config(\"spark.kubernetes.container.image\", \"inseefrlab/jupyter-datascience:py3.9.7-spark3.2.0\")\\\n",
    "        .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\", os.environ['KUBERNETES_SERVICE_ACCOUNT'])\\\n",
    "        .config(\"spark.executor.instances\", \"4\")\\\n",
    "        .config(\"spark.executor.memory\", \"4g\")\\\n",
    "        .config(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE'])\\\n",
    "        .getOrCreate()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|Id_1|Id_2|Me_1|\n",
      "+----+----+----+\n",
      "|2010|   A|   5|\n",
      "|2010|   B|  11|\n",
      "|2010|   C|   0|\n",
      "|2010|   G|  19|\n",
      "|2010|   H|NULL|\n",
      "|2010|   I|  14|\n",
      "|2010|   M|   2|\n",
      "|2010|   N|   5|\n",
      "|2010|   O|   4|\n",
      "|2010|   P|   7|\n",
      "|2010|   Q|  -7|\n",
      "|2010|   S|   3|\n",
      "|2010|   T|   9|\n",
      "|2010|   U|NULL|\n",
      "|2010|   V|   6|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "root_path=\"../../data\"\n",
    "data_path=f\"{root_path}/check_hier_ds.csv\"\n",
    "\n",
    "df=spark.read.csv(data_path, header=True,inferSchema=True)\n",
    "df.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Implement hierarchical ruleset\n",
    "\n",
    "A hierarchical ruleset can contain one or more rules. For each rule, we need to define a corresponding validation function in spark that implements the logic and generate the resulting columns.\n",
    "\n",
    "Note it has 3 modes (e.g. invalid, all, all_measures), and each mode has a unique output column formats. So each generated function must take consideration of that.\n",
    "\n",
    "Below functions should be generated when we encounter **define datapoint ruleset**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# this function get the value of each operant\n",
    "def get_op_var(ds,reference_col,val_col,op_val):\n",
    "    return ds.filter(col(reference_col)==op_val).select(val_col).collect()[0][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "# this function is for complete the output column of check option : all\n",
    "def trans_for_all(ds,rule_id,error_code,error_level):\n",
    "    return ds.withColumn(\"rule_id\",lit(rule_id)) \\\n",
    "       .withColumn(\"error_code\",when(col(\"bool_var\")==False,error_code)) \\\n",
    "        .withColumn(\"error_level\",when(col(\"bool_var\")==False,error_level))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "reference_col=\"Id_2\"\n",
    "val_col=\"Me_1\"\n",
    "op1=\"A\"\n",
    "op2=\"J\"\n",
    "op3=\"K\"\n",
    "op4=\"L\"\n",
    "\n",
    "# get the value of op1\n",
    "val= get_op_var(df,reference_col,val_col,op1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "# implementation of rule R010 in HR_1, this should be generated based on HR_1:R010 definition\n",
    "def dpr1_1(ds,option):\n",
    "    rule_id=\"R010\"\n",
    "    cond_col=\"Id_3\"\n",
    "    cond_val=\"CREDIT\"\n",
    "    check_col=\"Me_1\"\n",
    "    check_val=0\n",
    "    error_code=\"Bad credit\"\n",
    "    error_level=\"5\"\n",
    "    if option==\"invalid\":\n",
    "        tmp=ds.filter((col(cond_col)==cond_val) & (col(check_col)<check_val) ).withColumnRenamed(check_col,\"obs_value\")\n",
    "        return trans_for_invalid(tmp,rule_id,error_code,error_level)\n",
    "    elif option==\"all\":\n",
    "        tmp=ds.withColumn(\"bool_var\",when((col(cond_col)==cond_val) & (col(check_col)<check_val),False).otherwise(True))\n",
    "        return trans_for_all(tmp,rule_id,error_code,error_level)\n",
    "    elif option==\"all_measures\":\n",
    "        return ds\n",
    "    else:\n",
    "        raise ValueError(\"Unknown option value, accepted values are : invalid, all, all_measures\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "dpr1_1_resu=dpr1_1(df,\"all\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "|Id_1|Id_2|  Id_3|Me_1|bool_var|rule_id|error_code|error_level|\n",
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "|2011|   1|CREDIT|  10|    true| dpr1_1|      null|       null|\n",
      "|2011|   1| DEBIT|  -2|    true| dpr1_1|      null|       null|\n",
      "|2012|   1|CREDIT|  10|    true| dpr1_1|      null|       null|\n",
      "|2012|   1| DEBIT|   2|    true| dpr1_1|      null|       null|\n",
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dpr1_1_resu.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# implementation of rule dpr1_2 in dpr1, this should be generated based on dpr1 definition\n",
    "def dpr1_2(ds,option):\n",
    "    rule_id=\"dpr1_2\"\n",
    "    cond_col=\"Id_3\"\n",
    "    cond_val=\"DEBIT\"\n",
    "    check_col=\"Me_1\"\n",
    "    check_val=0\n",
    "    error_code=\"Bad debit\"\n",
    "    error_level=\"6\"\n",
    "    if option==\"invalid\":\n",
    "        tmp=ds.filter((col(cond_col)==cond_val) & (col(check_col)<check_val) ).withColumnRenamed(check_col,\"obs_value\")\n",
    "        return trans_for_invalid(tmp,rule_id,error_code,error_level)\n",
    "    elif option==\"all\":\n",
    "        tmp=ds.withColumn(\"bool_var\",when((col(cond_col)==cond_val) & (col(check_col)<check_val),False).otherwise(True))\n",
    "        return trans_for_all(tmp,rule_id,error_code,error_level)\n",
    "    elif option==\"all_measures\":\n",
    "        return ds\n",
    "    else:\n",
    "        raise ValueError(\"Unknown option value, accepted values are : invalid, all, all_measures\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "dpr1_2_resu=dpr1_2(df,\"all\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "|Id_1|Id_2|  Id_3|Me_1|bool_var|rule_id|error_code|error_level|\n",
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "|2011|   1|CREDIT|  10|    true| dpr1_2|      null|       null|\n",
      "|2011|   1| DEBIT|  -2|   false| dpr1_2| Bad debit|          6|\n",
      "|2012|   1|CREDIT|  10|    true| dpr1_2|      null|       null|\n",
      "|2012|   1| DEBIT|   2|    true| dpr1_2|      null|       null|\n",
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dpr1_2_resu.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "|Id_1|Id_2|  Id_3|Me_1|bool_var|rule_id|error_code|error_level|\n",
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "|2011|   1|CREDIT|  10|    true| dpr1_1|      null|       null|\n",
      "|2011|   1| DEBIT|  -2|    true| dpr1_1|      null|       null|\n",
      "|2012|   1|CREDIT|  10|    true| dpr1_1|      null|       null|\n",
      "|2012|   1| DEBIT|   2|    true| dpr1_1|      null|       null|\n",
      "|2011|   1|CREDIT|  10|    true| dpr1_2|      null|       null|\n",
      "|2011|   1| DEBIT|  -2|   false| dpr1_2| Bad debit|          6|\n",
      "|2012|   1|CREDIT|  10|    true| dpr1_2|      null|       null|\n",
      "|2012|   1| DEBIT|   2|    true| dpr1_2|      null|       null|\n",
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dpr1_1_resu.union(dpr1_2_resu).show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Apply data point ruleset on a data frame\n",
    "\n",
    "This function should be generated when a function **check_datapoint**,\n",
    "note the rule sets and rules are generated in step 1. They must be present when we call **check_datapoint**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "def data_validation(ds,rules,option):\n",
    "    result=rules[0](ds,option)\n",
    "    for i in range(1,len(rules)):\n",
    "        result=result.union(rules[i](ds,option))\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "rule_sets=[dpr1_1,dpr1_2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "invalid_resu=data_validation(df,rule_sets,\"invalid\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----+---------+-------+----------+-----------+\n",
      "|Id_1|Id_2| Id_3|obs_value|rule_id|error_code|error_level|\n",
      "+----+----+-----+---------+-------+----------+-----------+\n",
      "|2011|   1|DEBIT|       -2| dpr1_2| Bad debit|          6|\n",
      "+----+----+-----+---------+-------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "invalid_resu.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "all_resu=data_validation(df,rule_sets,\"all\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "|Id_1|Id_2|  Id_3|Me_1|bool_var|rule_id|error_code|error_level|\n",
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "|2011|   1|CREDIT|  10|    true| dpr1_1|      null|       null|\n",
      "|2011|   1| DEBIT|  -2|    true| dpr1_1|      null|       null|\n",
      "|2012|   1|CREDIT|  10|    true| dpr1_1|      null|       null|\n",
      "|2012|   1| DEBIT|   2|    true| dpr1_1|      null|       null|\n",
      "|2011|   1|CREDIT|  10|    true| dpr1_2|      null|       null|\n",
      "|2011|   1| DEBIT|  -2|   false| dpr1_2| Bad debit|          6|\n",
      "|2012|   1|CREDIT|  10|    true| dpr1_2|      null|       null|\n",
      "|2012|   1| DEBIT|   2|    true| dpr1_2|      null|       null|\n",
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_resu.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
