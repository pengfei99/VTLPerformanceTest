{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# VTL Check hierarchy\n",
    "\n",
    "The original doc can be found at **line 6399 of VTL-2.0-Reference-Manual**\n",
    "\n",
    "To use the check hierarchy, user need to define two parts:\n",
    "- define a  hierarchical ruleset:\n",
    "- define a check_hierarchy function:\n",
    "\n",
    "\n",
    "## 1. Define hierarchical ruleset\n",
    "\n",
    "The original doc can be found at **line 650 of VTL-2.0-Reference-Manual**\n",
    "\n",
    "### 1.1 Syntax\n",
    "Below is an example of how to define a new ruleset\n",
    "\n",
    "```text\n",
    "define hierarchical ruleset rulesetName ( hrRulesetSignature ) is\n",
    "hrRule\n",
    "{ ; hrRule }*\n",
    "end hierarchical ruleset\n",
    "```\n",
    "- **hrRulesetSignature**: The definition of parameters which the `hrRule` can use. (e.g. column names)\n",
    "- **hrRule**: the definition of a single rule\n",
    "\n",
    "### 1.2 Example\n",
    "\n",
    "``` text\n",
    "define hierarchical ruleset BeneluxRuleset ( valuedomain rule GeoArea) is\n",
    "Belgium = Belgium;\n",
    "Luxembourg = Luxembourg;\n",
    "Netherlands = Netherlands;\n",
    "Benelux = Belgium + Luxembourg + Netherlands\n",
    "end hierarchical ruleset\n",
    "```\n",
    "\n",
    "## 2. Define a check_hierarchy function\n",
    "\n",
    "### 2.1 Syntax\n",
    "\n",
    "```text\n",
    "check_hierarchy ( op , hr { condition condComp { , condComp }* } { rule ruleComp }\n",
    "{ mode } { input } { output } )\n",
    "  - mode ::= non_null | non_zero | partial_null | partial_zero | always_null | always_zero\n",
    "  - input ::= dataset | dataset_priority\n",
    "  - output ::= invalid | all | all_measures\n",
    "\n",
    "```\n",
    "\n",
    "- **op**: the Data Set to be checked\n",
    "- **hr**: the hierarchical Ruleset to be used\n",
    "- **condComp**: `condComp` is a Component of `op` to be associated (in positional order) to the conditioning Value Domains or Variables defined in `hr` (if any).\n",
    "- **ruleComp**: Component of `op`\n",
    "- **mode**: this parameter specifies how to treat the possible missing Data Points corresponding to the Code Items in the left and right sides of the rules and which Data Points are produced in output. The meaning of the possible values of the parameter is explained below.\n",
    "- **output**: specifies the Data Points and the Measures of the resulting Data Set:\n",
    "     - **invalid**: the resulting Data Set contains a Data Point for each Data Point of `op` and  each Rule in `dpr` that evaluates to `FALSE` on that Data Point. The resulting Data Set has the Measures of op.\n",
    "     - **all**: the resulting Data Set contains a data point for each Data Point of `op` and each Rule in `dpr`. The resulting Data Set has the boolean Measure bool_var.\n",
    "     - **all_measures**: the resulting Data Set contains a Data Point for each Data Point of `op` and each Rule in `dpr`. The resulting dataset has the Measures of `op` and the  boolean Measure bool_var.\n",
    "     - If not specified then output is assumed to be invalid. See the Behaviour for further details.\n",
    "\n",
    "### 2.2 Example\n",
    "\n",
    "```text\n",
    "DS_r := check_hierarchy ( DS_1, HR_1 rule Id_2 partial_null all )\n",
    "```\n",
    "\n",
    "- **DS_1** : is the input dataset\n",
    "- **HR_1** : is the ruleset\n",
    "- **rule Id_2**: is the column name of the `DS_1` which we be used by `HR_1`\n",
    "\n",
    "## 3. A complete example\n",
    "\n",
    "### 3.1. Dataset\n",
    "\n",
    "Suppose we have the below input dataset:\n",
    "\n",
    "```text\n",
    "Id_1,Geo_Area,Me_1\n",
    "2010,Italia,5\n",
    "2010,France,11\n",
    "2010,Germany,8\n",
    "2010,Europe,23\n",
    "2010,Algeria,5\n",
    "2010,Gongo,11\n",
    "2010,Zimbabwe,8\n",
    "2010,Africa,24\n",
    "2010,China,8\n",
    "2010,Japan,7\n",
    "2010,Laos,6\n",
    "2010,Asia,21\n",
    "```\n",
    "\n",
    "### 3.2 Define hierarchical ruleset.\n",
    "\n",
    "```text\n",
    "define hierarchical ruleset HR_1 ( valuedomain rule GeoArea ) is\n",
    "   R010 : Europe = Italia + France + Germany errorcode Bad_val errorlevel 5;\n",
    "   R020 : Africa = Algeria + Gongo + Zimbabwe errorcode Bad_val errorlevel 5;\n",
    "   R030 : Asia = China + Japan + Laos errorcode Bad_val errorlevel 1\n",
    "```\n",
    "\n",
    "### 3.3 Define the check_hierarchy() function\n",
    "\n",
    "```text\n",
    "DS_r := check_hierarchy ( DS_1, HR_1 rule GeoArea partial_null all )\n",
    "```\n",
    "\n",
    "The output should be:\n",
    "\n",
    "```text\n",
    "\n",
    "Id_1,GeoArea,Me_1,Bool_var,imbalance,errorcode,errorlevel\n",
    "2010,Italia,5,NULL,NULL,NULL,5\n",
    "2010,France,11,NULL,NULL,NULL,5\n",
    "2010,Germany,8,NULL,NULL,NULL,5\n",
    "2010,Europe,23,FALSE,-1,Bad_val,5\n",
    "2010,Algeria,5,NULL,NULL,NULL,5\n",
    "2010,Gongo,11,NULL,NULL,NULL,5\n",
    "2010,Zimbabwe,8,NULL,NULL,NULL,5\n",
    "2010,Africa,24,TRUE,0,Bad_val,5\n",
    "2010,China,8,NULL,NULL,NULL,5\n",
    "2010,Japan,7,NULL,NULL,NULL,5\n",
    "2010,Laos,6,NULL,NULL,NULL,5\n",
    "2010,Asia,21,TRUE,0,Bad_val,1\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession,DataFrame\n",
    "\n",
    "import os\n",
    "from pyspark.sql.functions import col, lit, when,sum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/12 12:06:15 WARN Utils: Your hostname, pengfei-Virtual-Machine resolves to a loopback address: 127.0.1.1; using 10.50.2.80 instead (on interface eth0)\n",
      "23/05/12 12:06:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/12 12:06:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "local = True\n",
    "\n",
    "if local:\n",
    "    spark = SparkSession.builder \\\n",
    "        .master(\"local[4]\") \\\n",
    "        .appName(\"VTLValidation_check_hierarchy\")\\\n",
    "        .getOrCreate()\n",
    "else:\n",
    "    spark = SparkSession.builder\\\n",
    "        .master(\"k8s://https://kubernetes.default.svc:443\") \\\n",
    "        .appName(\"VTLValidation_check_hierarchy\")\\\n",
    "        .config(\"spark.kubernetes.container.image\", \"inseefrlab/jupyter-datascience:py3.9.7-spark3.2.0\")\\\n",
    "        .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\", os.environ['KUBERNETES_SERVICE_ACCOUNT'])\\\n",
    "        .config(\"spark.executor.instances\", \"4\")\\\n",
    "        .config(\"spark.executor.memory\", \"4g\")\\\n",
    "        .config(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE'])\\\n",
    "        .getOrCreate()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----+\n",
      "|Id_1|Geo_Area|Me_1|\n",
      "+----+--------+----+\n",
      "|2010|  Italia|   5|\n",
      "|2010|  France|  11|\n",
      "|2010| Germany|   8|\n",
      "|2010|  Europe|  23|\n",
      "|2010| Algeria|   5|\n",
      "|2010|   Gongo|  11|\n",
      "|2010|Zimbabwe|   8|\n",
      "|2010|  Africa|  24|\n",
      "|2010|   China|   8|\n",
      "|2010|   Japan|   7|\n",
      "|2010|    Laos|   6|\n",
      "|2010|    Asia|  21|\n",
      "+----+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "root_path=\"../../data\"\n",
    "data_path=f\"{root_path}/check_hier_ds.csv\"\n",
    "\n",
    "df=spark.read.csv(data_path, header=True,inferSchema=True)\n",
    "df.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3 Implement check hierarchy in spark\n",
    "\n",
    "A hierarchical ruleset can contain one or more rules. For each rule, we need to define a corresponding validation function in spark that implements the logic and generate the resulting columns.\n",
    "\n",
    "Note it has 3 modes (e.g. invalid, all, all_measures), and each mode has a unique output column formats. So each generated function must take consideration of that.\n",
    "\n",
    "Below functions should be generated when we encounter **define datapoint ruleset**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# this function get the value of each operant\n",
    "def get_op_var(ds,reference_col,val_col,op_val):\n",
    "    cell=ds.filter(col(reference_col)==op_val).select(val_col).collect()\n",
    "    if len(cell) and len(cell[0]):\n",
    "        return cell[0][0]\n",
    "    else:\n",
    "        raise TypeError"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# this function is for complete the output column of check option : all\n",
    "def trans_for_all(ds,rule_id,error_code,error_level):\n",
    "    return ds.withColumn(\"rule_id\",lit(rule_id)) \\\n",
    "       .withColumn(\"error_code\",when(col(\"bool_var\")==False,error_code)) \\\n",
    "        .withColumn(\"error_level\",when(col(\"bool_var\")==False,error_level))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# implementation of rule R010 in HR_1, this should be generated based on HR_1:R010 definition\n",
    "# Europe = Italia + France + Germany\n",
    "def r010(ds,option):\n",
    "    rule_id=\"R010\"\n",
    "    reference_col=\"Geo_Area\"\n",
    "    val_col=\"Me_1\"\n",
    "    op1=\"Europe\"\n",
    "    op2=\"Italia\"\n",
    "    op3=\"France\"\n",
    "    op4=\"Germany\"\n",
    "\n",
    "    # get the value of op1\n",
    "    try:\n",
    "        val1= get_op_var(df,reference_col,val_col,op1)\n",
    "        val2=get_op_var(df,reference_col,val_col,op2)\n",
    "        val3=get_op_var(df,reference_col,val_col,op3)\n",
    "        val4=get_op_var(df,reference_col,val_col,op4)\n",
    "        print(f\"{op1}: {val1}, {op2}: {val2}, {op3}: {val3}, {op4} : {val4}\")\n",
    "        imbalance=val1-val2-val3-val4\n",
    "    except TypeError:\n",
    "        imbalance=None\n",
    "    error_code=\"Bad val\"\n",
    "    error_level=\"5\"\n",
    "    if option==\"invalid\":\n",
    "        tmp=ds.filter(col(reference_col)==op1)\\\n",
    "            .withColumn(\"imbalance\",lit(imbalance))\n",
    "        tmp = tmp.withColumn(\"bool_var\", when(tmp.imbalance == 0, \"True\")\n",
    "                                        .when(tmp.imbalance.isNull() , \"None\")\n",
    "                                        .otherwise(\"False\"))\n",
    "        tmp = tmp.withColumn(\"error_code\",lit(error_code)).withColumn(\"error_level\",lit(error_level))\n",
    "        return tmp\n",
    "    elif option==\"all\":\n",
    "\n",
    "        return 1\n",
    "    elif option==\"all_measures\":\n",
    "        return ds\n",
    "    else:\n",
    "        raise ValueError(\"Unknown option value, accepted values are : invalid, all, all_measures\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Europe: 23, Italia: 5, France: 11, Germany : 8\n"
     ]
    }
   ],
   "source": [
    "r010_resu=r010(df,\"invalid\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----+---------+--------+----------+-----------+\n",
      "|Id_1|Geo_Area|Me_1|imbalance|bool_var|error_code|error_level|\n",
      "+----+--------+----+---------+--------+----------+-----------+\n",
      "|2010|  Europe|  23|       -1|   False|   Bad val|          5|\n",
      "+----+--------+----+---------+--------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r010_resu.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# implementation of rule R010 in HR_1, this should be generated based on HR_1:R010 definition\n",
    "# Europe = Italia + France + Germany\n",
    "def r020(ds,option):\n",
    "    rule_id=\"R020\"\n",
    "    reference_col=\"Geo_Area\"\n",
    "    val_col=\"Me_1\"\n",
    "    op1=\"Africa\"\n",
    "    op2=\"Algeria\"\n",
    "    op3=\"Gongo\"\n",
    "    op4=\"Zimbabwe\"\n",
    "\n",
    "    # get the value of op1\n",
    "    try:\n",
    "        val1= get_op_var(df,reference_col,val_col,op1)\n",
    "        val2=get_op_var(df,reference_col,val_col,op2)\n",
    "        val3=get_op_var(df,reference_col,val_col,op3)\n",
    "        val4=get_op_var(df,reference_col,val_col,op4)\n",
    "        print(f\"{op1}: {val1}, {op2}: {val2}, {op3}: {val3}, {op4} : {val4}\")\n",
    "        imbalance=val1-val2-val3-val4\n",
    "    except TypeError:\n",
    "        imbalance=None\n",
    "    error_code=\"Bad val\"\n",
    "    error_level=\"5\"\n",
    "    if option==\"invalid\":\n",
    "        tmp=ds.filter(col(reference_col)==op1)\\\n",
    "            .withColumn(\"imbalance\",lit(imbalance))\n",
    "\n",
    "        tmp = tmp.withColumn(\"bool_var\", when(tmp.imbalance == 0, \"True\")\n",
    "                                        .when(tmp.imbalance.isNull() , \"None\")\n",
    "                                        .otherwise(\"False\"))\n",
    "        tmp = tmp.withColumn(\"error_code\",lit(error_code)).withColumn(\"error_level\",lit(error_level))\n",
    "        return tmp\n",
    "    elif option==\"all\":\n",
    "\n",
    "        return 1\n",
    "    elif option==\"all_measures\":\n",
    "        return ds\n",
    "    else:\n",
    "        raise ValueError(\"Unknown option value, accepted values are : invalid, all, all_measures\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Africa: 24, Algeria: 5, Gongo: 11, Zimbabwe : 8\n"
     ]
    }
   ],
   "source": [
    "r020_resu=r020(df,\"invalid\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----+---------+--------+----------+-----------+\n",
      "|Id_1|Geo_Area|Me_1|imbalance|bool_var|error_code|error_level|\n",
      "+----+--------+----+---------+--------+----------+-----------+\n",
      "|2010|  Africa|  24|        0|    True|   Bad val|          5|\n",
      "+----+--------+----+---------+--------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r020_resu.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# implementation of rule R010 in HR_1, this should be generated based on HR_1:R010 definition\n",
    "# Europe = Italia + France + Germany\n",
    "def r030(ds,option):\n",
    "    rule_id=\"R030\"\n",
    "    reference_col=\"Geo_Area\"\n",
    "    val_col=\"Me_1\"\n",
    "    op1=\"Asia\"\n",
    "    op2=\"China\"\n",
    "    op3=\"Japan\"\n",
    "    op4=\"Laos\"\n",
    "\n",
    "    # get the value of op1\n",
    "    try:\n",
    "        val1= get_op_var(df,reference_col,val_col,op1)\n",
    "        val2=get_op_var(df,reference_col,val_col,op2)\n",
    "        val3=get_op_var(df,reference_col,val_col,op3)\n",
    "        val4=get_op_var(df,reference_col,val_col,op4)\n",
    "        print(f\"{op1}: {val1}, {op2}: {val2}, {op3}: {val3}, {op4} : {val4}\")\n",
    "        imbalance=val1-val2-val3-val4\n",
    "    except TypeError:\n",
    "        imbalance=None\n",
    "    error_code=\"Bad val\"\n",
    "    error_level=\"5\"\n",
    "    if option==\"invalid\":\n",
    "        tmp=ds.filter(col(reference_col)==op1)\\\n",
    "            .withColumn(\"imbalance\",lit(imbalance))\n",
    "        tmp = tmp.withColumn(\"bool_var\", when(tmp.imbalance == 0, \"True\")\n",
    "                                        .when(tmp.imbalance.isNull() , \"None\")\n",
    "                                        .otherwise(\"False\"))\n",
    "        tmp = tmp.withColumn(\"error_code\",lit(error_code)).withColumn(\"error_level\",lit(error_level))\n",
    "        return tmp\n",
    "    elif option==\"all\":\n",
    "\n",
    "        return 1\n",
    "    elif option==\"all_measures\":\n",
    "        return ds\n",
    "    else:\n",
    "        raise ValueError(\"Unknown option value, accepted values are : invalid, all, all_measures\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asia: 21, China: 8, Japan: 7, Laos : 6\n"
     ]
    }
   ],
   "source": [
    "r030_resu=r030(df,\"invalid\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----+---------+--------+----------+-----------+\n",
      "|Id_1|Geo_Area|Me_1|imbalance|bool_var|error_code|error_level|\n",
      "+----+--------+----+---------+--------+----------+-----------+\n",
      "|2010|    Asia|  21|        0|    True|   Bad val|          5|\n",
      "+----+--------+----+---------+--------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r030_resu.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "finalDf=r010_resu.union(r020_resu).union(r030_resu)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----+---------+--------+----------+-----------+\n",
      "|Id_1|Geo_Area|Me_1|imbalance|bool_var|error_code|error_level|\n",
      "+----+--------+----+---------+--------+----------+-----------+\n",
      "|2010|  Europe|  23|       -1|   False|   Bad val|          5|\n",
      "|2010|  Africa|  24|        0|    True|   Bad val|          5|\n",
      "|2010|    Asia|  21|        0|    True|   Bad val|          5|\n",
      "+----+--------+----+---------+--------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalDf.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. What borders me\n",
    "\n",
    "There are two major problems of the function `check_hierarchy`:\n",
    "\n",
    "- Mix of different information in the same column\n",
    "- The calculation of rows instead of columns will kill the performance. With small data, the row approach may work, but with big data, it will fail.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. What we propose\n",
    "\n",
    "Let's retake the above example.\n",
    "\n",
    "We propose to separate the dataset into two dataset with a common key called `Continent`\n",
    "\n",
    "```text\n",
    "Id_1,Country,Me_1,Continent\n",
    "2010,Italia,5,Europe\n",
    "2010,France,11,Europe\n",
    "2010,Germany,8,Europe\n",
    "2010,Algeria,5,Africa\n",
    "2010,Gongo,11,Africa\n",
    "2010,Zimbabwe,8,Africa\n",
    "2010,China,8,Asia\n",
    "2010,Japan,7,Asia\n",
    "2010,Laos,6,Asia\n",
    "```\n",
    "\n",
    "```text\n",
    "Id_1,Continent,Me_1\n",
    "2010,Europe,23\n",
    "2010,Africa,24\n",
    "2010,Asia,21\n",
    "```\n",
    "\n",
    "DS_r := check_hierarchy ( DS_1, HR_1 rule GeoArea partial_null all )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "country_path=f\"{root_path}/check_hier_ds_country.csv\"\n",
    "\n",
    "df_country=spark.read.csv(country_path, header=True,inferSchema=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id_1: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Me_1: integer (nullable = true)\n",
      " |-- Continent: string (nullable = true)\n",
      "\n",
      "+----+--------+----+---------+\n",
      "|Id_1| Country|Me_1|Continent|\n",
      "+----+--------+----+---------+\n",
      "|2010|  Italia|   5|   Europe|\n",
      "|2010|  France|  11|   Europe|\n",
      "|2010| Germany|   8|   Europe|\n",
      "|2010| Algeria|   5|   Africa|\n",
      "|2010|   Gongo|  11|   Africa|\n",
      "|2010|Zimbabwe|   8|   Africa|\n",
      "|2010|   China|   8|     Asia|\n",
      "|2010|   Japan|   7|     Asia|\n",
      "|2010|    Laos|   6|     Asia|\n",
      "+----+--------+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_country.printSchema()\n",
    "df_country.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "continent_path=f\"{root_path}/check_hier_ds_continent.csv\"\n",
    "\n",
    "df_continent=spark.read.csv(continent_path, header=True,inferSchema=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id_1: integer (nullable = true)\n",
      " |-- Continent: string (nullable = true)\n",
      " |-- Me_1: integer (nullable = true)\n",
      "\n",
      "+----+---------+----+\n",
      "|Id_1|Continent|Me_1|\n",
      "+----+---------+----+\n",
      "|2010|   Europe|  23|\n",
      "|2010|   Africa|  24|\n",
      "|2010|     Asia|  21|\n",
      "+----+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_continent.printSchema()\n",
    "df_continent.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "df_sum=df_country.groupBy(\"Continent\").agg(sum(\"Me_1\").alias(\"country_sum_me1\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+\n",
      "|Continent|country_sum_me1|\n",
      "+---------+---------------+\n",
      "|   Europe|             24|\n",
      "|   Africa|             24|\n",
      "|     Asia|             21|\n",
      "+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sum.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "# join the two df\n",
    "df_resu=df_sum.join(df_continent,\"Continent\",\"inner\")\n",
    "\n",
    "# create the column imbalance|bool_var|error_code|error_level|\n",
    "df_resu=df_resu.withColumn(\"imbalance\",col(\"Me_1\")-col(\"country_sum_me1\"))\n",
    "\n",
    "df_resu=df_resu.withColumn(\"bool_var\",when(col(\"imbalance\")==0,True)\n",
    "                                      .when(col(\"imbalance\").isNull(),None)\n",
    "                                      .otherwise(False))\\\n",
    "                .withColumn(\"error_code\",lit(\"Bad val\"))\\\n",
    "                .withColumn(\"error_level\",lit(5)).drop(\"country_sum_me1\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----+---------+--------+----------+-----------+\n",
      "|Continent|Id_1|Me_1|imbalance|bool_var|error_code|error_level|\n",
      "+---------+----+----+---------+--------+----------+-----------+\n",
      "|   Europe|2010|  23|       -1|   false|   Bad val|          5|\n",
      "|   Africa|2010|  24|        0|    true|   Bad val|          5|\n",
      "|     Asia|2010|  21|        0|    true|   Bad val|          5|\n",
      "+---------+----+----+---------+--------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_resu.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
