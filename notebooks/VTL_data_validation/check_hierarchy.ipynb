{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# VTL Check data point\n",
    "\n",
    "The original doc can be found at **line 6319 of VTL-2.0-Reference-Manual**\n",
    "## Syntax\n",
    "\n",
    "```text\n",
    "check_datapoint ( op , dpr { components listComp } { output } )\n",
    "   - listComp ::= comp { , comp }*\n",
    "   - output ::= invalid | all | all_measures\n",
    "\n",
    "```\n",
    "\n",
    "- **op**: the Data Set to check 6326\n",
    "- **dpr**: the Data Point Ruleset to be used 6327\n",
    "- **listComp**: if `dpr` is defined on Value Domains then `listComp` is the list of Components of `op` to be associated (in positional order) to the conditioning Value Domains defined in `dpr`. If `dpr` is defined on Variables then listComp is the list of Components of op to be associated (in positional order) to the conditioning Variables defined in dpr (for documentation purposes).\n",
    "- **comp**: Component of `op`\n",
    "- **output**: specifies the Data Points and the Measures of the resulting Data Set:\n",
    "     - **invalid**: the resulting Data Set contains a Data Point for each Data Point of `op` and  each Rule in `dpr` that evaluates to `FALSE` on that Data Point. The resulting Data Set has the Measures of op.\n",
    "     - **all**: the resulting Data Set contains a data point for each Data Point of `op` and each Rule in `dpr`. The resulting Data Set has the boolean Measure bool_var.\n",
    "     - **all_measures**: the resulting Data Set contains a Data Point for each Data Point of `op` and each Rule in `dpr`. The resulting dataset has the Measures of `op` and the  boolean Measure bool_var.\n",
    "     - If not specified then output is assumed to be invalid. See the Behaviour for further details.\n",
    "\n",
    "## Example\n",
    "\n",
    "Step 1. Define `dpr`\n",
    "\n",
    "```text\n",
    "define datapoint ruleset dpr1 ( variable Id_3, Me_1 ) is\n",
    "        # the rule of dpr1_1\n",
    "        when Id_3 = “CREDIT” then Me_1 >= 0 errorcode “Bad credit” errorlevel 5;\n",
    "        # the rule of dpr1_2\n",
    "        when Id_3 = “DEBIT” then Me_1 >= 0 errorcode “Bad debit” errorlevel 6\n",
    "end datapoint ruleset\n",
    "```\n",
    "\n",
    "Step 2. Apply `dpr` on `ds`\n",
    "\n",
    "Given the Data Set DS_1:\n",
    "```text\n",
    "DS_1,Id_1,Id_2,Id_3,Me_1\n",
    "2011,1,CREDIT,10\n",
    "2011,1,DEBIT,-2\n",
    "2012,1,CREDIT,10\n",
    "2012,1,DEBIT,2\n",
    "```\n",
    "\n",
    "DS_r := check_datapoint ( DS_1, dpr1 ) results in:\n",
    "\n",
    "```text\n",
    "Id_1,Id_2,Id_3,ruleid,obs_value,errorcode,errorlevel\n",
    "2011,1,DEBIT,dpr1_2,-2,Bad debit,null\n",
    "```\n",
    "\n",
    "DS_r := check_datapoint ( DS_1, dpr1 all ) results in:\n",
    "\n",
    "```text\n",
    "Id_1,Id_2,Id_3,ruleid,bool_var,errorcode,errorlevel\n",
    "2011,1,CREDIT,dpr1_1,true,null,null\n",
    "2011,1,CREDIT,dpr1_2,true,null,null\n",
    "2011,1,DEBIT,dpr1_1,true,null,null\n",
    "2011,1,DEBIT,dpr1_2,false,Bad debit,null\n",
    "2012,1,CREDIT,dpr1_1,true,null,null\n",
    "2012,1,CREDIT,dpr1_2,true,null,null\n",
    "2012,1,DEBIT,dpr1_1,true,null,null\n",
    "2012,1,DEBIT,dpr1_2,true,null,null\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession,DataFrame\n",
    "\n",
    "import os\n",
    "from pyspark.sql.functions import col, lit, when\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/11 10:58:44 WARN Utils: Your hostname, pengfei-Virtual-Machine resolves to a loopback address: 127.0.1.1; using 10.50.2.80 instead (on interface eth0)\n",
      "22/10/11 10:58:44 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/11 10:58:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "local = True\n",
    "\n",
    "if local:\n",
    "    spark = SparkSession.builder \\\n",
    "        .master(\"local[4]\") \\\n",
    "        .appName(\"VTLValidation\")\\\n",
    "        .getOrCreate()\n",
    "else:\n",
    "    spark = SparkSession.builder\\\n",
    "        .master(\"k8s://https://kubernetes.default.svc:443\") \\\n",
    "        .appName(\"VTLValidation\")\\\n",
    "        .config(\"spark.kubernetes.container.image\", \"inseefrlab/jupyter-datascience:py3.9.7-spark3.2.0\")\\\n",
    "        .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\", os.environ['KUBERNETES_SERVICE_ACCOUNT'])\\\n",
    "        .config(\"spark.executor.instances\", \"4\")\\\n",
    "        .config(\"spark.executor.memory\", \"4g\")\\\n",
    "        .config(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE'])\\\n",
    "        .getOrCreate()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+----+\n",
      "|Id_1|Id_2|  Id_3|Me_1|\n",
      "+----+----+------+----+\n",
      "|2011|   1|CREDIT|  10|\n",
      "|2011|   1| DEBIT|  -2|\n",
      "|2012|   1|CREDIT|  10|\n",
      "|2012|   1| DEBIT|   2|\n",
      "+----+----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "root_path=\"../../data\"\n",
    "data_path=f\"{root_path}/validation_ds.csv\"\n",
    "\n",
    "df=spark.read.csv(data_path, header=True,inferSchema=True)\n",
    "df.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Implement data point ruleset\n",
    "\n",
    "A data point ruleset can contain one or more rules. For each rule, we need to define a corresponding validation function in spark that implements the logic and generate the resulting columns.\n",
    "\n",
    "Note it has 3 modes (e.g. invalid, all, all_measures), and each mode has a unique output column formats. So each generated function must take consideration of that.\n",
    "\n",
    "Below functions should be generated when we encounter **define datapoint ruleset**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "# this function is for complete the output column of check option : invalid\n",
    "def trans_for_invalid(ds,rule_id,error_code,error_level):\n",
    "    return ds.withColumn(\"rule_id\",lit(rule_id)) \\\n",
    "       .withColumn(\"error_code\",lit(error_code)) \\\n",
    "        .withColumn(\"error_level\",lit(error_level))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "# this function is for complete the output column of check option : all\n",
    "def trans_for_all(ds,rule_id,error_code,error_level):\n",
    "    return ds.withColumn(\"rule_id\",lit(rule_id)) \\\n",
    "       .withColumn(\"error_code\",when(col(\"bool_var\")==False,error_code)) \\\n",
    "        .withColumn(\"error_level\",when(col(\"bool_var\")==False,error_level))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "# implementation of rule dpr1_1 in dpr1, this should be generated based on dpr1 definition\n",
    "def dpr1_1(ds,option):\n",
    "    rule_id=\"dpr1_1\"\n",
    "    cond_col=\"Id_3\"\n",
    "    cond_val=\"CREDIT\"\n",
    "    check_col=\"Me_1\"\n",
    "    check_val=0\n",
    "    error_code=\"Bad credit\"\n",
    "    error_level=\"5\"\n",
    "    if option==\"invalid\":\n",
    "        tmp=ds.filter((col(cond_col)==cond_val) & (col(check_col)<check_val) ).withColumnRenamed(check_col,\"obs_value\")\n",
    "        return trans_for_invalid(tmp,rule_id,error_code,error_level)\n",
    "    elif option==\"all\":\n",
    "        tmp=ds.withColumn(\"bool_var\",when((col(cond_col)==cond_val) & (col(check_col)<check_val),False).otherwise(True))\n",
    "        return trans_for_all(tmp,rule_id,error_code,error_level)\n",
    "    elif option==\"all_measures\":\n",
    "        return ds\n",
    "    else:\n",
    "        raise ValueError(\"Unknown option value, accepted values are : invalid, all, all_measures\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "dpr1_1_resu=dpr1_1(df,\"all\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "|Id_1|Id_2|  Id_3|Me_1|bool_var|rule_id|error_code|error_level|\n",
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "|2011|   1|CREDIT|  10|    true| dpr1_1|      null|       null|\n",
      "|2011|   1| DEBIT|  -2|    true| dpr1_1|      null|       null|\n",
      "|2012|   1|CREDIT|  10|    true| dpr1_1|      null|       null|\n",
      "|2012|   1| DEBIT|   2|    true| dpr1_1|      null|       null|\n",
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dpr1_1_resu.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# implementation of rule dpr1_2 in dpr1, this should be generated based on dpr1 definition\n",
    "def dpr1_2(ds,option):\n",
    "    rule_id=\"dpr1_2\"\n",
    "    cond_col=\"Id_3\"\n",
    "    cond_val=\"DEBIT\"\n",
    "    check_col=\"Me_1\"\n",
    "    check_val=0\n",
    "    error_code=\"Bad debit\"\n",
    "    error_level=\"6\"\n",
    "    if option==\"invalid\":\n",
    "        tmp=ds.filter((col(cond_col)==cond_val) & (col(check_col)<check_val) ).withColumnRenamed(check_col,\"obs_value\")\n",
    "        return trans_for_invalid(tmp,rule_id,error_code,error_level)\n",
    "    elif option==\"all\":\n",
    "        tmp=ds.withColumn(\"bool_var\",when((col(cond_col)==cond_val) & (col(check_col)<check_val),False).otherwise(True))\n",
    "        return trans_for_all(tmp,rule_id,error_code,error_level)\n",
    "    elif option==\"all_measures\":\n",
    "        return ds\n",
    "    else:\n",
    "        raise ValueError(\"Unknown option value, accepted values are : invalid, all, all_measures\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "dpr1_2_resu=dpr1_2(df,\"all\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "|Id_1|Id_2|  Id_3|Me_1|bool_var|rule_id|error_code|error_level|\n",
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "|2011|   1|CREDIT|  10|    true| dpr1_2|      null|       null|\n",
      "|2011|   1| DEBIT|  -2|   false| dpr1_2| Bad debit|          6|\n",
      "|2012|   1|CREDIT|  10|    true| dpr1_2|      null|       null|\n",
      "|2012|   1| DEBIT|   2|    true| dpr1_2|      null|       null|\n",
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dpr1_2_resu.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "|Id_1|Id_2|  Id_3|Me_1|bool_var|rule_id|error_code|error_level|\n",
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "|2011|   1|CREDIT|  10|    true| dpr1_1|      null|       null|\n",
      "|2011|   1| DEBIT|  -2|    true| dpr1_1|      null|       null|\n",
      "|2012|   1|CREDIT|  10|    true| dpr1_1|      null|       null|\n",
      "|2012|   1| DEBIT|   2|    true| dpr1_1|      null|       null|\n",
      "|2011|   1|CREDIT|  10|    true| dpr1_2|      null|       null|\n",
      "|2011|   1| DEBIT|  -2|   false| dpr1_2| Bad debit|          6|\n",
      "|2012|   1|CREDIT|  10|    true| dpr1_2|      null|       null|\n",
      "|2012|   1| DEBIT|   2|    true| dpr1_2|      null|       null|\n",
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dpr1_1_resu.union(dpr1_2_resu).show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Apply data point ruleset on a data frame\n",
    "\n",
    "This function should be generated when a function **check_datapoint**,\n",
    "note the rule sets and rules are generated in step 1. They must be present when we call **check_datapoint**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "def data_validation(ds,rules,option):\n",
    "    result=rules[0](ds,option)\n",
    "    for i in range(1,len(rules)):\n",
    "        result=result.union(rules[i](ds,option))\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "rule_sets=[dpr1_1,dpr1_2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "invalid_resu=data_validation(df,rule_sets,\"invalid\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----+---------+-------+----------+-----------+\n",
      "|Id_1|Id_2| Id_3|obs_value|rule_id|error_code|error_level|\n",
      "+----+----+-----+---------+-------+----------+-----------+\n",
      "|2011|   1|DEBIT|       -2| dpr1_2| Bad debit|          6|\n",
      "+----+----+-----+---------+-------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "invalid_resu.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "all_resu=data_validation(df,rule_sets,\"all\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "|Id_1|Id_2|  Id_3|Me_1|bool_var|rule_id|error_code|error_level|\n",
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "|2011|   1|CREDIT|  10|    true| dpr1_1|      null|       null|\n",
      "|2011|   1| DEBIT|  -2|    true| dpr1_1|      null|       null|\n",
      "|2012|   1|CREDIT|  10|    true| dpr1_1|      null|       null|\n",
      "|2012|   1| DEBIT|   2|    true| dpr1_1|      null|       null|\n",
      "|2011|   1|CREDIT|  10|    true| dpr1_2|      null|       null|\n",
      "|2011|   1| DEBIT|  -2|   false| dpr1_2| Bad debit|          6|\n",
      "|2012|   1|CREDIT|  10|    true| dpr1_2|      null|       null|\n",
      "|2012|   1| DEBIT|   2|    true| dpr1_2|      null|       null|\n",
      "+----+----+------+----+--------+-------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_resu.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
