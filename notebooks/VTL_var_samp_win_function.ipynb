{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8a092da-e2b9-46e9-a26f-d56b4eaa75e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession,DataFrame\n",
    "from pyspark.sql.types import StructField, StructType, StringType, DoubleType, IntegerType, LongType, DecimalType\n",
    "import os\n",
    "from pyspark.sql.functions import lit, count, var_samp\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c03a6e5-1662-4a99-862e-dc505ea075f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "local = True\n",
    "\n",
    "if local:\n",
    "    spark = SparkSession.builder \\\n",
    "        .master(\"local[4]\") \\\n",
    "        .appName(\"VTLAnalytic\")\\\n",
    "        .getOrCreate()\n",
    "else:\n",
    "    spark = SparkSession.builder\\\n",
    "        .master(\"k8s://https://kubernetes.default.svc:443\") \\\n",
    "        .appName(\"VTLAnalytic\")\\\n",
    "        .config(\"spark.kubernetes.container.image\", \"inseefrlab/jupyter-datascience:py3.9.7-spark3.2.0\")\\\n",
    "        .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\", os.environ['KUBERNETES_SERVICE_ACCOUNT'])\\\n",
    "        .config(\"spark.executor.instances\", \"4\")\\\n",
    "        .config(\"spark.executor.memory\", \"8g\")\\\n",
    "        .config(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE'])\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47881370-67c4-42ab-9b2b-a6b679a4523c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+----+----+\n",
      "|Id_1|Id_2|Id_3|Me_1|Me_2|\n",
      "+----+----+----+----+----+\n",
      "|   A|  XX|2000|   3|   1|\n",
      "|   A|  XX|2001|   4|   9|\n",
      "|   A|  XX|2002|   7|   5|\n",
      "|   A|  XX|2003|   6|   8|\n",
      "|   A|  YY|2000|   9|   3|\n",
      "|   A|  YY|2001|   5|   4|\n",
      "|   A|  YY|2002|  10|   2|\n",
      "|   A|  YY|2003|   5|   7|\n",
      "+----+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[(\"A\", \"XX\", 2000, 3, 1),\n",
    "    (\"A\", \"XX\", 2001, 4, 9),\n",
    "    (\"A\", \"XX\", 2002, 7, 5),\n",
    "    (\"A\", \"XX\", 2003, 6, 8),\n",
    "    (\"A\", \"YY\", 2000, 9, 3),\n",
    "    (\"A\", \"YY\", 2001, 5, 4),\n",
    "    (\"A\", \"YY\", 2002, 10, 2),\n",
    "    (\"A\", \"YY\", 2003, 5, 7)]\n",
    "\n",
    "schema=StructType([StructField(\"Id_1\",StringType(),True),\n",
    "                   StructField(\"Id_2\",StringType(),True),\n",
    "                   StructField(\"Id_3\",IntegerType(),True),\n",
    "                   StructField(\"Me_1\",IntegerType(),True),\n",
    "                   StructField(\"Me_2\",IntegerType(),True)])\n",
    "\n",
    "df=spark.createDataFrame(data, schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6ba1c1-3b84-4c74-9809-0edb270b7c51",
   "metadata": {},
   "source": [
    "## VarSamp Example\n",
    "\n",
    "pyspark.sql.functions.var_samp(col):\n",
    "\n",
    "Aggregate function: returns the unbiased sample variance of the values in a group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e0441ff-fe0c-4391-a6cd-0ab33c24ad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below calculation simulates the vtl syntax \"res := var_pop ( ds1 over ( partition by Id_1 order by Year range between 1 preceding and 1 following) );\"\n",
    "\n",
    "win_name=Window.partitionBy(\"Id_1\").orderBy(\"Id_3\").rangeBetween(-1,1)\n",
    "target_col1=\"Me_1\"\n",
    "target_col2=\"Me_2\"\n",
    "new_col_name1=f\"var_samp_{target_col1}\"\n",
    "new_col_name2=f\"var_samp_{target_col2}\"\n",
    "df_resu = df.withColumn(new_col_name1,var_samp(target_col1).over(win_name)) \\\n",
    "            .withColumn(new_col_name2,var_samp(target_col2).over(win_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7beabd7d-9a05-4776-a7a5-4453275804e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+----+----+-----------------+------------------+\n",
      "|Id_1|Id_2|Id_3|Me_1|Me_2|    var_samp_Me_1|     var_samp_Me_2|\n",
      "+----+----+----+----+----+-----------------+------------------+\n",
      "|   A|  XX|2000|   3|   1|6.916666666666667|11.583333333333334|\n",
      "|   A|  YY|2000|   9|   3|6.916666666666667|11.583333333333334|\n",
      "|   A|  XX|2001|   4|   9|7.866666666666667| 8.000000000000002|\n",
      "|   A|  YY|2001|   5|   4|7.866666666666667| 8.000000000000002|\n",
      "|   A|  XX|2002|   7|   5|4.566666666666666| 6.966666666666667|\n",
      "|   A|  YY|2002|  10|   2|4.566666666666666| 6.966666666666667|\n",
      "|   A|  XX|2003|   6|   8|4.666666666666667|               7.0|\n",
      "|   A|  YY|2003|   5|   7|4.666666666666667|               7.0|\n",
      "+----+----+----+----+----+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_resu.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ed2fb9-e0a8-4a3b-a0f8-1ce733919bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
